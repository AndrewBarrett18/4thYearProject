{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from sklearn.preprocessing import normalize\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import tensorflow as tf\n",
    "import os,glob\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessYolo(object_path):\n",
    "    # Preprocesses Yolo outputs to (m, 30, 12) to input to lstm where m is number of 30-frame testing sequences\n",
    "    \n",
    "    with open(object_path) as f:\n",
    "        dictionary = json.load(f)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for image in dictionary:\n",
    "        if len(dictionary[image]) > 3:\n",
    "            dictionary[image] = dictionary[image][0:3]\n",
    "\n",
    "        while len(dictionary[image]) < 3:\n",
    "            dictionary[image].append([0,0,0,0,0,0])\n",
    "\n",
    "        data.append(dictionary[image])\n",
    "\n",
    "    outerlist = []\n",
    "    innerlist = []\n",
    "    megalist = []\n",
    "    x = 1\n",
    "\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            for k in range(4):\n",
    "                innerlist.append(j[k])\n",
    "\n",
    "            if x % 3 == 0:\n",
    "                outerlist.append(innerlist)\n",
    "                innerlist = []\n",
    "\n",
    "                if len(outerlist) % 30 == 0:\n",
    "                    megalist.append(outerlist)\n",
    "                    outerlist = []\n",
    "\n",
    "            x = x + 1\n",
    "\n",
    "    while len(outerlist) % 30 != 0:\n",
    "        outerlist.append([0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "    if len(outerlist) == 30:\n",
    "        megalist.append(outerlist)\n",
    "        \n",
    "    return np.array(megalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeYolo(yolo):\n",
    "    # Normalizes the yolo output before inputting to lstm\n",
    "    \n",
    "    reshaped = []\n",
    "\n",
    "    for i in range(yolo.shape[0]):\n",
    "        reshaped.append([yolo[i, :, 0], yolo[i, :, 1], yolo[i, :, 2], yolo[i, :, 3], yolo[i, :, 4], yolo[i, :, 5],\n",
    "                         yolo[i, :, 6], yolo[i, :, 7], yolo[i, :, 8], yolo[i, :, 9], yolo[i, :, 10], yolo[i, :, 11]])\n",
    "\n",
    "    reshaped = np.array(reshaped).astype(np.float)\n",
    "\n",
    "    norm = np.zeros(reshaped.shape)\n",
    "    minmax = np.zeros((reshaped.shape[0], reshaped.shape[1], 2))\n",
    "\n",
    "    for i in range(reshaped.shape[0]):\n",
    "        for j in range(reshaped.shape[1]):\n",
    "            min_val = np.amin(reshaped[i, j])\n",
    "            max_val = np.amax(reshaped[i, j])\n",
    "            minmax[i, j, 0] = min_val\n",
    "            minmax[i, j, 1] = max_val\n",
    "            if max_val - min_val != 0:\n",
    "                for k in range(reshaped.shape[2]):\n",
    "                    norm[i, j, k] = (float(reshaped[i, j, k]) - min_val)/(max_val - min_val)\n",
    "            else:\n",
    "                norm[i, j, :] = reshaped[i, j, :]\n",
    "\n",
    "    yolo_norm = np.zeros(yolo.shape)\n",
    "\n",
    "    for i in range(norm.shape[0]):\n",
    "        for j in range(norm.shape[1]):\n",
    "            for k in range(norm.shape[2]):\n",
    "                yolo_norm[i, k, j] = norm[i, j, k]\n",
    "                \n",
    "    return yolo_norm, minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(model_path):\n",
    "    # Loads a pre-trained model from json architecture file and h5 weights file\n",
    "\n",
    "    with open(os.path.join(model_path, 'modelacc.json'),'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    model.load_weights(os.path.join(model_path, 'modelacc.h5'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lane detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 30, 32)            5760      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 24)            5472      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 24)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30, 12)            300       \n",
      "=================================================================\n",
      "Total params: 11,532\n",
      "Trainable params: 11,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13/13 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "object_path = os.path.join(os.path.split(Path.cwd())[0], 'Images/JSON/data.json')\n",
    "model_path = os.path.join(os.path.split(Path.cwd())[0], 'KittiLSTM')\n",
    "lane_path = os.path.join(os.path.split(Path.cwd())[0], 'Images/JSON/inf_data.json')\n",
    "\n",
    "yolo = preprocessYolo(object_path)\n",
    "yolo_norm, minmax = normalizeYolo(yolo)\n",
    "\n",
    "model = loadModel(model_path)\n",
    "model.summary()\n",
    "predictions = model.predict(yolo_norm, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 30, 12)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_data = []\n",
    "\n",
    "with open(lane_path) as f:\n",
    "    for line in f:\n",
    "        if line:\n",
    "            lane_data.append(json.loads(line))\n",
    "\n",
    "# Lane Preprocessing\n",
    "lane_curves = {}\n",
    "\n",
    "for image in lane_data:\n",
    "    for key in image:\n",
    "        llist = []\n",
    "        h_samples_list = []\n",
    "        for i in range(0,len(image[key]['lanes'])):\n",
    "            llist = []\n",
    "            \n",
    "            if image[key]['lanes'][i]:\n",
    "                llist = image[key]['lanes'][i]\n",
    "                hlist = image[key]['h_samples'][i]\n",
    "                curve_coeffs = np.polyfit(np.array(llist), np.array(hlist), 2)\n",
    "                y = np.linspace(np.amin(llist),np.amax(llist))\n",
    "                \n",
    "                if key in lane_curves.keys():\n",
    "                    lane_curves[key].append(((curve_coeffs[0] * y ** 2+ curve_coeffs[1] * y + curve_coeffs[2]), y))\n",
    "                else:\n",
    "                    lane_curves[key] = [((curve_coeffs[0] * y ** 2+ curve_coeffs[1] * y + curve_coeffs[2]), y)]\n",
    "                    \n",
    "dummy_counter = 0\n",
    "\n",
    "for key in lane_curves.keys():\n",
    "    for lane in range(0, len(lane_curves[key])):\n",
    "        try:\n",
    "            if lane_curves[key][lane][1][-1] < lane_curves[key][lane+1][1][-1]:\n",
    "                dummy = lane_curves[key][lane+1]\n",
    "                lane_curves[key][lane+1] = lane_curves[key][lane]\n",
    "                lane_curves[key][lane] = dummy\n",
    "        except:\n",
    "            dummy_counter +=1\n",
    "\n",
    "# Un-normalizing the predictions         \n",
    "pred_norm = np.zeros(predictions.shape)\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    for j in range(predictions.shape[1]):\n",
    "        for k in range(predictions.shape[2]):\n",
    "            pred_norm[i, j, k] = (predictions[i, j, k] * \n",
    "                                  (y_minmax[i, k, 1] - y_minmax[i, k, 0]))+ y_minmax[i, k, 0]\n",
    "            \n",
    "# Finding the centre points of the predictions\n",
    "pred_centre = []\n",
    "\n",
    "for sequence in pred_norm:\n",
    "    centre_list = []\n",
    "    for tuples in sequence:\n",
    "        obj_1_centre = ((tuples[2] + tuples[0])/2, (tuples[3] + tuples[1])/2)\n",
    "        obj_2_centre = ((tuples[6] + tuples[4])/2, (tuples[7] + tuples[5])/2)\n",
    "        obj_3_centre = ((tuples[10] + tuples[8])/2, (tuples[11] + tuples[9])/2)\n",
    "        centre_list.append((obj_1_centre, obj_2_centre, obj_3_centre))\n",
    "    pred_centre.append(centre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
