{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from sklearn.preprocessing import normalize\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import tensorflow as tf\n",
    "import os,glob\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessYolo(object_path):\n",
    "# Preprocesses Yolo outputs to (m, 30, 12) to input to lstm where m is number of 30-frame testing sequences\n",
    "    \n",
    "    with open(object_path) as f:\n",
    "        dictionary = json.load(f)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for image in dictionary:\n",
    "        if len(dictionary[image]) > 3:\n",
    "            dictionary[image] = dictionary[image][0:3]\n",
    "\n",
    "        while len(dictionary[image]) < 3:\n",
    "            dictionary[image].append([0,0,0,0,0,0])\n",
    "\n",
    "        data.append(dictionary[image])\n",
    "\n",
    "    outerlist = []\n",
    "    innerlist = []\n",
    "    megalist = []\n",
    "    x = 1\n",
    "\n",
    "    for i in data:\n",
    "        for j in i:\n",
    "            for k in range(4):\n",
    "                innerlist.append(j[k])\n",
    "\n",
    "            if x % 3 == 0:\n",
    "                outerlist.append(innerlist)\n",
    "                innerlist = []\n",
    "\n",
    "                if len(outerlist) % 30 == 0:\n",
    "                    megalist.append(outerlist)\n",
    "                    outerlist = []\n",
    "\n",
    "            x = x + 1\n",
    "\n",
    "    while len(outerlist) % 30 != 0:\n",
    "        outerlist.append([0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "\n",
    "    if len(outerlist) == 30:\n",
    "        megalist.append(outerlist)\n",
    "        \n",
    "    return np.array(megalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeYolo(yolo):\n",
    "# Normalizes the yolo output before inputting to lstm\n",
    "    \n",
    "    reshaped = []\n",
    "\n",
    "    for i in range(yolo.shape[0]):\n",
    "        reshaped.append([yolo[i, :, 0], yolo[i, :, 1], yolo[i, :, 2], yolo[i, :, 3], yolo[i, :, 4], yolo[i, :, 5],\n",
    "                         yolo[i, :, 6], yolo[i, :, 7], yolo[i, :, 8], yolo[i, :, 9], yolo[i, :, 10], yolo[i, :, 11]])\n",
    "\n",
    "    reshaped = np.array(reshaped).astype(np.float)\n",
    "\n",
    "    norm = np.zeros(reshaped.shape)\n",
    "    minmax = np.zeros((reshaped.shape[0], reshaped.shape[1], 2))\n",
    "\n",
    "    for i in range(reshaped.shape[0]):\n",
    "        for j in range(reshaped.shape[1]):\n",
    "            min_val = np.amin(reshaped[i, j])\n",
    "            max_val = np.amax(reshaped[i, j])\n",
    "            minmax[i, j, 0] = min_val\n",
    "            minmax[i, j, 1] = max_val\n",
    "            if max_val - min_val != 0:\n",
    "                for k in range(reshaped.shape[2]):\n",
    "                    norm[i, j, k] = (float(reshaped[i, j, k]) - min_val)/(max_val - min_val)\n",
    "            else:\n",
    "                norm[i, j, :] = reshaped[i, j, :]\n",
    "\n",
    "    yolo_norm = np.zeros(yolo.shape)\n",
    "\n",
    "    for i in range(norm.shape[0]):\n",
    "        for j in range(norm.shape[1]):\n",
    "            for k in range(norm.shape[2]):\n",
    "                yolo_norm[i, k, j] = norm[i, j, k]\n",
    "                \n",
    "    return yolo_norm, minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(model_path):\n",
    "# Loads a pre-trained model from json architecture file and h5 weights file\n",
    "\n",
    "    with open(os.path.join(model_path, 'modelacc.json'),'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    model.load_weights(os.path.join(model_path, 'modelacc.h5'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectLaneChange(lane_path, predictions, minmax):\n",
    "# Detects whether a lane change has occured given the lstm prediction, lane detection file, and normalization \n",
    "# parameters    \n",
    "\n",
    "    lane_data = []\n",
    "    lane_frames = []\n",
    "\n",
    "    with open(lane_path) as f:\n",
    "        for line in f:\n",
    "            if line:\n",
    "                lane_data.append(json.loads(line))\n",
    "\n",
    "    # Lane Preprocessing\n",
    "    lane_curves = {}\n",
    "\n",
    "    for image in lane_data:\n",
    "        for key in image:\n",
    "            lane_frames.append(int(key.split('.')[0]))\n",
    "            llist = []\n",
    "            h_samples_list = []\n",
    "            for i in range(0,len(image[key]['lanes'])):\n",
    "                llist = []\n",
    "\n",
    "                if image[key]['lanes'][i]:\n",
    "                    llist = image[key]['lanes'][i]\n",
    "                    hlist = image[key]['h_samples'][i]\n",
    "                    curve_coeffs = np.polyfit(np.array(llist), np.array(hlist), 2)\n",
    "                    y = np.linspace(np.amin(llist),np.amax(llist))\n",
    "\n",
    "                    if key in lane_curves.keys():\n",
    "                        lane_curves[key].append(((curve_coeffs[0] * y ** 2+ curve_coeffs[1] * y + curve_coeffs[2]), y))\n",
    "                    else:\n",
    "                        lane_curves[key] = [((curve_coeffs[0] * y ** 2+ curve_coeffs[1] * y + curve_coeffs[2]), y)]\n",
    "\n",
    "    dummy_counter = 0\n",
    "\n",
    "    for key in lane_curves.keys():\n",
    "        for lane in range(0, len(lane_curves[key])):\n",
    "            try:\n",
    "                if lane_curves[key][lane][1][-1] < lane_curves[key][lane+1][1][-1]:\n",
    "                    dummy = lane_curves[key][lane+1]\n",
    "                    lane_curves[key][lane+1] = lane_curves[key][lane]\n",
    "                    lane_curves[key][lane] = dummy\n",
    "            except:\n",
    "                dummy_counter +=1\n",
    "\n",
    "    # Un-normalizing the predictions         \n",
    "    pred_norm = np.zeros(predictions.shape)\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        for j in range(predictions.shape[1]):\n",
    "            for k in range(predictions.shape[2]):\n",
    "                pred_norm[i, j, k] = (predictions[i, j, k] * \n",
    "                                      (minmax[i, k, 1] - minmax[i, k, 0]))+ minmax[i, k, 0]\n",
    "\n",
    "    # Finding the centre points of the predictions\n",
    "    pred_centre = []\n",
    "\n",
    "    for sequence in pred_norm:\n",
    "        centre_list = []\n",
    "        for tuples in sequence:\n",
    "            obj_1_centre = ((tuples[2] + tuples[0])/2, (tuples[3] + tuples[1])/2)\n",
    "            obj_2_centre = ((tuples[6] + tuples[4])/2, (tuples[7] + tuples[5])/2)\n",
    "            obj_3_centre = ((tuples[10] + tuples[8])/2, (tuples[11] + tuples[9])/2)\n",
    "            centre_list.append((obj_1_centre, obj_2_centre, obj_3_centre))\n",
    "        pred_centre.append(centre_list)\n",
    "\n",
    "    pred_centre = np.array(pred_centre)\n",
    "    pred_centre = pred_centre.reshape(1, pred_centre.shape[0]*pred_centre.shape[1], 3, 2)\n",
    "    pred_centre = pred_centre.tolist()\n",
    "\n",
    "    # Determining whether a lane change has occurred or not\n",
    "    obj_states = [0, 0, 0]\n",
    "    obj_changes = []\n",
    "    lane_changed_obj = []\n",
    "    image_offest = int(lane_frames[0])\n",
    "\n",
    "\n",
    "    for object_pairs in pred_centre[0]:\n",
    "        for object_centre in object_pairs:\n",
    "            current_obj = object_pairs.index(object_centre)\n",
    "            object_region = obj_states[current_obj]\n",
    "            current_obj_state = object_region\n",
    "            for key in lane_curves.keys():\n",
    "                current_lane = list(lane_curves.keys()).index(key)   \n",
    "                if ('00' + str(pred_centre[0].index(object_pairs)+ image_offest) + '.') in key:\n",
    "                    current_state = 0\n",
    "                    lane_quart_points = []\n",
    "                    for i in range(0, len(lane_curves[key])):\n",
    "                        xquart = lane_curves[key][i][1][0]\n",
    "                        lane_quart_points.append(xquart)\n",
    "\n",
    "                    for quart_point in lane_quart_points:\n",
    "                        if (object_centre[0] < quart_point) and quart_point - 30 < object_centre[0]:\n",
    "                            current_state += 1                \n",
    "                    if (current_state) != object_region:\n",
    "                        obj_changes.append((key, current_obj))\n",
    "                        obj_states[current_obj] = current_state\n",
    "\n",
    "            if len(obj_changes) > 3:\n",
    "                if obj_changes[-1][1] == obj_changes[-2][1] == obj_changes[-3][1]:\n",
    "                    if (obj_changes[-2], obj_changes[-1]) not in lane_changed_obj:\n",
    "                        if int((obj_changes[-3][0]).split('.')[0]) + 5 >= int((obj_changes[-2][0]).split('.')[0]):\n",
    "                            lane_changed_obj.append((obj_changes[-2], obj_changes[-1]))\n",
    "    obj_count = []\n",
    "    for pairs in lane_changed_obj:\n",
    "        obj_count.append(pairs[0][1])\n",
    "    if len(lane_changed_obj) > 3 or len(lane_changed_obj) == 0:\n",
    "        print('No lane change detected')\n",
    "    else:\n",
    "        print('Lane change occuring from: ' + lane_changed_obj[0][0][0] + ' -> '+ lane_changed_obj[-1][1][0])  \n",
    "        print('Object: ' + str(mode(obj_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 30, 32)            5760      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 24)            5472      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 24)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30, 12)            300       \n",
      "=================================================================\n",
      "Total params: 11,532\n",
      "Trainable params: 11,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9/9 [==============================] - 0s 55ms/step\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RankWarning: Polyfit may be poorly conditioned\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No lane change detected\n"
     ]
    }
   ],
   "source": [
    "object_path = os.path.join(os.path.split(Path.cwd())[0], 'Images/JSON/data.json')\n",
    "model_path = os.path.join(os.path.split(Path.cwd())[0], 'KittiLSTM')\n",
    "lane_path = os.path.join(os.path.split(Path.cwd())[0], 'Images/JSON/inf_data.json')\n",
    "\n",
    "yolo = preprocessYolo(object_path)\n",
    "yolo_norm, minmax = normalizeYolo(yolo)\n",
    "\n",
    "model = loadModel(model_path)\n",
    "model.summary()\n",
    "\n",
    "predictions = model.predict(yolo_norm, verbose=1)\n",
    "\n",
    "print(\"\\n\")\n",
    "detectLaneChange(lane_path, predictions, minmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
